# Large File Upload

This program uploads a large file to Databricks using the Files API.

## Features

- Uploads files up to 5 GB using the Databricks Files API
- Supports Unity Catalog volumes
- Shows upload progress and statistics
- Verifies upload by checking file metadata
- Uses efficient streaming upload

## Prerequisites

1. **Databricks Configuration**: Make sure you have a Databricks profile configured
2. **Large File**: You need a large file to upload (e.g., generated by the file generator)
3. **Unity Catalog Volume**: The target volume must exist and be accessible

## Configuration

Update the configuration in `main.go`:

```go
cfg := &databricks.Config{
    Profile: "your-profile-name", // Update this to your profile
}
```

And update the remote file path:

```go
remoteFilePath := "/Volumes/your-catalog/your-schema/your-volume/your-file.bin"
```

## Usage

1. **First, generate a large file** (if you haven't already):
   ```bash
   cd examples/large-file-generator
   go run main.go
   ```

2. **Upload the file**:
   ```bash
   cd examples/large-file-upload
   go run main.go
   ```

The program will:
- Check if the local file exists
- Display file information
- Upload the file to the specified remote path
- Show upload statistics (time taken, speed)
- Verify the upload by checking file metadata

## Output

The program will show:
- File information before upload
- Upload progress
- Final upload statistics
- Verification results

## Error Handling

The program includes comprehensive error handling for:
- Missing local files
- Network connectivity issues
- Authentication problems
- File system errors

## Notes

- The Files API supports files up to 5 GB
- For very large files, the API automatically uses multipart upload
- The upload is verified by checking the file's content length
- Make sure you have sufficient permissions on the target volume 