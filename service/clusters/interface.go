// Code generated from OpenAPI specs by Databricks SDK Generator. DO NOT EDIT.

package clusters

import (
	"context"
	"time"
)

// <needs content added>
//
// This is the high-level interface, that contains generated methods.
//
// Evolving: this interface is under development. Method signatures may change.
type ClustersService interface {

	// Allowing admins to change cluster owner
	ChangeOwner(ctx context.Context, request ChangeClusterOwner) error

	// Creates a new Spark cluster. This method will acquire new instances from
	// the cloud provider if necessary. This method is asynchronous; the
	// returned ``cluster_id`` can be used to poll the cluster status. When this
	// method returns, the cluster will be in a ``PENDING`` state. The cluster
	// will be usable once it enters a ``RUNNING`` state. Note: Databricks may
	// not be able to acquire some of the requested nodes, due to cloud provider
	// limitations (account limits, spot price, ...) or transient network
	// issues. If Databricks acquires at least 85% of the requested on-demand
	// nodes, cluster creation will succeed. Otherwise the cluster will
	// terminate with an informative error message. An example request: ..
	// code:: { "cluster_name": "my-cluster", "spark_version":
	// "2.0.x-scala2.10", "node_type_id": "r3.xlarge", "spark_conf": {
	// "spark.speculation": true }, "aws_attributes": { "availability": "SPOT",
	// "zone_id": "us-west-2a" }, "num_workers": 25 } See below as an example
	// for an autoscaling cluster. Note that this cluster will start with `2`
	// nodes, the minimum. .. code:: { "cluster_name": "autoscaling-cluster",
	// "spark_version": "2.0.x-scala2.10", "node_type_id": "r3.xlarge",
	// "autoscale" : { "min_workers": 2, "max_workers": 50 } }
	Create(ctx context.Context, request CreateCluster) (*CreateClusterResponse, error)

	// CreateAndWait calls Create() and waits to reach RUNNING state
	//
	// This method is generated by Databricks SDK Code Generator.
	CreateAndWait(ctx context.Context, request CreateCluster, timeout ...time.Duration) (*ClusterInfo, error)

	// Terminates a Spark cluster given its id. The cluster is removed
	// asynchronously. Once the termination has completed, the cluster will be
	// in a ``TERMINATED`` state. If the cluster is already in a ``TERMINATING``
	// or ``TERMINATED`` state, nothing will happen. An example request: ..
	// code:: { "cluster_id": "1202-211320-brick1" }
	Delete(ctx context.Context, request DeleteCluster) error

	// DeleteAndWait calls Delete() and waits to reach TERMINATED state
	//
	// This method is generated by Databricks SDK Code Generator.
	DeleteAndWait(ctx context.Context, request DeleteCluster, timeout ...time.Duration) (*ClusterInfo, error)
	// DeleteByClusterId calls Delete, but directly with primitive function arguments,
	// instead of constructing request instance.
	//
	// This method is generated by Databricks SDK Code Generator.
	DeleteByClusterId(ctx context.Context, clusterId string) error

	// DeleteByClusterIdAndWait calls DeleteByClusterId and waits until ClusterInfo is in desired state.
	//
	// This method is generated by Databricks SDK Code Generator.
	DeleteByClusterIdAndWait(ctx context.Context, clusterId string, timeout ...time.Duration) (*ClusterInfo, error)

	// Edits the configuration of a cluster to match the provided attributes and
	// size. A cluster can be edited if it is in a ``RUNNING`` or ``TERMINATED``
	// state. If a cluster is edited while in a ``RUNNING`` state, it will be
	// restarted so that the new attributes can take effect. If a cluster is
	// edited while in a ``TERMINATED`` state, it will remain ``TERMINATED``.
	// The next time it is started using the ``clusters/start`` API, the new
	// attributes will take effect. An attempt to edit a cluster in any other
	// state will be rejected with an ``INVALID_STATE`` error code. Clusters
	// created by the Databricks Jobs service cannot be edited. An example
	// request: .. code:: { "cluster_id": "1202-211320-brick1", "num_workers":
	// 10, "spark_version": "3.3.x-scala2.11", "node_type_id": "i3.2xlarge" }
	Edit(ctx context.Context, request EditCluster) error

	// EditAndWait calls Edit() and waits to reach RUNNING state
	//
	// This method is generated by Databricks SDK Code Generator.
	EditAndWait(ctx context.Context, request EditCluster, timeout ...time.Duration) (*ClusterInfo, error)

	// Retrieves a list of events about the activity of a cluster. This API is
	// paginated. If there are more events to read, the response includes all
	// the parameters necessary to request the next page of events. An example
	// request: ``/clusters/events?cluster_id=1202-211320-brick1`` An example
	// response: { "events": [ { "cluster_id": "1202-211320-brick1",
	// "timestamp": 1509572145487, "event_type": "RESTARTING", "event_details":
	// { "username": "admin" } }, ... { "cluster_id": "1202-211320-brick1",
	// "timestamp": 1509505807923, "event_type": "TERMINATING", "event_details":
	// { "termination_reason": { "code": "USER_REQUEST", "parameters": [
	// "username": "admin" ] } } ], "next_page": { "cluster_id":
	// "1202-211320-brick1", "end_time": 1509572145487, "order": "DESC",
	// "offset": 50 }, "total_count": 303 } Example request to retrieve the next
	// page of events
	// ``/clusters/events?cluster_id=1202-211320-brick1&end_time=1509572145487&order=DESC&offset=50``
	Events(ctx context.Context, request GetEvents) (*GetEventsResponse, error)

	// Retrieves the information for a cluster given its identifier. Clusters
	// can be described while they are running, or up to 60 days after they are
	// terminated. An example request:
	// ``/clusters/get?cluster_id=1202-211320-brick1``
	Get(ctx context.Context, request GetRequest) (*ClusterInfo, error)

	// GetAndWait calls Get() and waits to reach RUNNING state
	//
	// This method is generated by Databricks SDK Code Generator.
	GetAndWait(ctx context.Context, request GetRequest, timeout ...time.Duration) (*ClusterInfo, error)
	// GetByClusterId calls Get, but directly with primitive function arguments,
	// instead of constructing request instance.
	//
	// This method is generated by Databricks SDK Code Generator.
	GetByClusterId(ctx context.Context, clusterId string) (*ClusterInfo, error)

	// GetByClusterIdAndWait calls GetByClusterId and waits until ClusterInfo is in desired state.
	//
	// This method is generated by Databricks SDK Code Generator.
	GetByClusterIdAndWait(ctx context.Context, clusterId string, timeout ...time.Duration) (*ClusterInfo, error)

	// Returns information about all pinned clusters, currently active clusters,
	// up to 70 of the most recently terminated interactive clusters in the past
	// 7 days, and up to 30 of the most recently terminated job clusters in the
	// past 7 days. For example, if there is 1 pinned cluster, 4 active
	// clusters, 45 terminated interactive clusters in the past 7 days, and 50
	// terminated job clusters in the past 7 days, then this API returns the 1
	// pinned cluster, 4 active clusters, all 45 terminated interactive
	// clusters, and the 30 most recently terminated job clusters.
	List(ctx context.Context, request ListRequest) (*ListClustersResponse, error)

	// ListByCanUseClient calls List, but directly with primitive function arguments,
	// instead of constructing request instance.
	//
	// This method is generated by Databricks SDK Code Generator.
	ListByCanUseClient(ctx context.Context, canUseClient string) (*ListClustersResponse, error)

	// Returns a list of supported Spark node types. These node types can be
	// used to launch a cluster.
	ListNodeTypes(ctx context.Context) (*ListNodeTypesResponse, error)

	// Returns a list of availability zones where clusters can be created in
	// (ex: us-west-2a). These zones can be used to launch a cluster.
	ListZones(ctx context.Context) (*ListAvailableZonesResponse, error)

	// Permanently deletes a Spark cluster. This cluster is terminated and
	// resources are asynchronously removed. In addition, users will no longer
	// see permanently deleted clusters in the cluster list, and API users can
	// no longer perform any action on permanently deleted clusters. An example
	// request: .. code:: { "cluster_id": "1202-211320-brick1" }
	PermanentDelete(ctx context.Context, request PermanentDeleteCluster) error

	// PermanentDeleteByClusterId calls PermanentDelete, but directly with primitive function arguments,
	// instead of constructing request instance.
	//
	// This method is generated by Databricks SDK Code Generator.
	PermanentDeleteByClusterId(ctx context.Context, clusterId string) error

	// Pinning a cluster ensures that the cluster will always be returned by the
	// ListClusters API. Pinning a cluster that is already pinned will have no
	// effect. This API can only be called by workspace admins. An example
	// request: ``/clusters/pin?cluster_id=1202-211320-brick1``
	Pin(ctx context.Context, request PinCluster) error

	// PinByClusterId calls Pin, but directly with primitive function arguments,
	// instead of constructing request instance.
	//
	// This method is generated by Databricks SDK Code Generator.
	PinByClusterId(ctx context.Context, clusterId string) error

	// Resizes a cluster to have a desired number of workers. This will fail
	// unless the cluster is in a ``RUNNING`` state. An example request: ..
	// code:: { "cluster_id": "1202-211320-brick1", "num_workers": 30 }
	Resize(ctx context.Context, request ResizeCluster) error

	// ResizeAndWait calls Resize() and waits to reach RUNNING state
	//
	// This method is generated by Databricks SDK Code Generator.
	ResizeAndWait(ctx context.Context, request ResizeCluster, timeout ...time.Duration) (*ClusterInfo, error)

	// Restarts a Spark cluster given its id. If the cluster is not currently in
	// a ``RUNNING`` state, nothing will happen. An example request: .. code:: {
	// "cluster_id": "1202-211320-brick1" }
	Restart(ctx context.Context, request RestartCluster) error

	// RestartAndWait calls Restart() and waits to reach RUNNING state
	//
	// This method is generated by Databricks SDK Code Generator.
	RestartAndWait(ctx context.Context, request RestartCluster, timeout ...time.Duration) (*ClusterInfo, error)

	// Returns the list of available Spark versions. These versions can be used
	// to launch a cluster.
	SparkVersions(ctx context.Context) (*GetSparkVersionsResponse, error)

	// Starts a terminated Spark cluster given its id. This works similar to
	// `createCluster` except: - The previous cluster id and attributes are
	// preserved. - The cluster starts with the last specified cluster size. -
	// If the previous cluster was an autoscaling cluster, the current cluster
	// starts with the minimum number of nodes. - If the cluster is not
	// currently in a ``TERMINATED`` state, nothing will happen. - Clusters
	// launched to run a job cannot be started. An example request: .. code:: {
	// "cluster_id": "1202-211320-brick1" }
	Start(ctx context.Context, request StartCluster) error

	// StartAndWait calls Start() and waits to reach RUNNING state
	//
	// This method is generated by Databricks SDK Code Generator.
	StartAndWait(ctx context.Context, request StartCluster, timeout ...time.Duration) (*ClusterInfo, error)
	// StartByClusterId calls Start, but directly with primitive function arguments,
	// instead of constructing request instance.
	//
	// This method is generated by Databricks SDK Code Generator.
	StartByClusterId(ctx context.Context, clusterId string) error

	// StartByClusterIdAndWait calls StartByClusterId and waits until ClusterInfo is in desired state.
	//
	// This method is generated by Databricks SDK Code Generator.
	StartByClusterIdAndWait(ctx context.Context, clusterId string, timeout ...time.Duration) (*ClusterInfo, error)

	// Unpinning a cluster will allow the cluster to eventually be removed from
	// the ListClusters API. Unpinning a cluster that is not pinned will have no
	// effect. This API can only be called by workspace admins. An example
	// request: ``/clusters/unpin?cluster_id=1202-211320-brick1``
	Unpin(ctx context.Context, request UnpinCluster) error

	// UnpinByClusterId calls Unpin, but directly with primitive function arguments,
	// instead of constructing request instance.
	//
	// This method is generated by Databricks SDK Code Generator.
	UnpinByClusterId(ctx context.Context, clusterId string) error

	// GetOrCreateRunningCluster creates an autoterminating cluster if it doesn't exist
	GetOrCreateRunningCluster(ctx context.Context, name string, custom ...CreateCluster) (c *ClusterInfo, err error)
}
